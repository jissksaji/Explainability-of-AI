{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainability in AI\n",
    "\n",
    "In this notebook, you will investigate one technique to explain the output of a blackbox model. You will use sklearn to implement a small pipeline applying a multilayer perceptron (vanilla feed-forward neural network) to the [sklearn breast cancer dataset](https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-wisconsin-diagnostic-dataset) and explain the feature importance in the model afterwards.\n",
    "\n",
    "I will first demonstrate the pipeline exemplary on a [RidgeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html) that already ships the feature importances by construction in an interpretable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "SEMINAR_TOPIC_NUMBER = 3\n",
    "TOPIC_1_DECISION_TREE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "\n",
    "The Breast Cancer Dataset was introduced by [Street et al. in 1993](https://minds.wisconsin.edu/bitstream/handle/1793/59692/TR1131.pdf?sequence=1). A more detailed description can be found on the [sklearn page for the dataset](https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-wisconsin-diagnostic-dataset). The data is extracted from gray-scale images of fine needle aspirate (FNA) of breast tissue. From that, the nuclei were investigated and all features relate to the nuclei in the sample tissue.\n",
    "\n",
    "We can directly load it from sklearn and inspect it. As the dataset contains 10 predictive variables described by their mean, SE, and, worst; so, 30 variables in total. To simplify the task, we shrink down the dataset to 10 variables (we keep the variables describing the mean values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius</th>\n",
       "      <th>texture</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>area</th>\n",
       "      <th>smoothness</th>\n",
       "      <th>compactness</th>\n",
       "      <th>concavity</th>\n",
       "      <th>points</th>\n",
       "      <th>symmetry</th>\n",
       "      <th>dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius  texture  perimeter    area  smoothness  compactness  concavity  \\\n",
       "0     17.99    10.38     122.80  1001.0     0.11840      0.27760    0.30010   \n",
       "1     20.57    17.77     132.90  1326.0     0.08474      0.07864    0.08690   \n",
       "2     19.69    21.25     130.00  1203.0     0.10960      0.15990    0.19740   \n",
       "3     11.42    20.38      77.58   386.1     0.14250      0.28390    0.24140   \n",
       "4     20.29    14.34     135.10  1297.0     0.10030      0.13280    0.19800   \n",
       "..      ...      ...        ...     ...         ...          ...        ...   \n",
       "564   21.56    22.39     142.00  1479.0     0.11100      0.11590    0.24390   \n",
       "565   20.13    28.25     131.20  1261.0     0.09780      0.10340    0.14400   \n",
       "566   16.60    28.08     108.30   858.1     0.08455      0.10230    0.09251   \n",
       "567   20.60    29.33     140.10  1265.0     0.11780      0.27700    0.35140   \n",
       "568    7.76    24.54      47.92   181.0     0.05263      0.04362    0.00000   \n",
       "\n",
       "      points  symmetry  dimension  target  \n",
       "0    0.14710    0.2419    0.07871       0  \n",
       "1    0.07017    0.1812    0.05667       0  \n",
       "2    0.12790    0.2069    0.05999       0  \n",
       "3    0.10520    0.2597    0.09744       0  \n",
       "4    0.10430    0.1809    0.05883       0  \n",
       "..       ...       ...        ...     ...  \n",
       "564  0.13890    0.1726    0.05623       0  \n",
       "565  0.09791    0.1752    0.05533       0  \n",
       "566  0.05302    0.1590    0.05648       0  \n",
       "567  0.15200    0.2397    0.07016       0  \n",
       "568  0.00000    0.1587    0.05884       1  \n",
       "\n",
       "[569 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = datasets.load_breast_cancer(as_frame=True)\n",
    "dataset = data['frame'].iloc[:, :10]\n",
    "dataset[\"target\"] = data['frame']['target']\n",
    "dataset.columns = list(map(lambda x: x.split(\" \")[-1], dataset.columns))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Pipeline\n",
    "\n",
    "First, we extract the X values (variable matrix) and y values (targets) from the dataset. For the demonstration, we use a RidgeClassifier as model to be explained. Set ``SEMINAR_TOPIC_NUMBER`` in the top-most cell to enable the model for your topic instead. Then, the data needs to be split into a train set and a test set. A validation set is not necessary, as we will not optimize the models. In the pipeline, we first transform the parameters to have 0 mean and standard deviation of 1. This ensures comparability of coefficients. Then, we put in the model.\n",
    "\n",
    "Finally, we fit the pipeline and evaluate the models performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2668195477.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    match SEMINAR_TOPIC_NUMBER:\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "X = dataset.iloc[:, :10]\n",
    "y = dataset['target']\n",
    "\n",
    "# create models\n",
    "match SEMINAR_TOPIC_NUMBER:\n",
    "    case 1:\n",
    "        model = DecisionTreeClassifier(criterion=\"gini\") if TOPIC_1_DECISION_TREE else RandomForestClassifier(criterion=\"gini\")\n",
    "    case 2:\n",
    "        model = SVC(kernel=\"linear\")\n",
    "    case 3:\n",
    "        model = RidgeClassifier(alpha=0.00001, fit_intercept=False)\n",
    "    case _:\n",
    "        model = MLPClassifier()\n",
    "\n",
    "# prepare the pipeline\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "pipeline = Pipeline([('scaler', StandardScaler()), ('model', model)])\n",
    "pipeline.fit(X_train, y_train)\n",
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainability\n",
    "\n",
    "This is where the interesting part (YOUR part) starts. I demonstrated how it could look like for the RidgeClassifier. Depending on your explainability method, you can use other/different visualization methods, whatever your tool offers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(model, \u001b[39m\"\u001b[39m\u001b[39mcoef_\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[39m# Visualize the model coefficients as an example\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     plt\u001b[39m.\u001b[39mbar(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(dataset\u001b[39m.\u001b[39mcolumns) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m), model\u001b[39m.\u001b[39mcoef_[\u001b[39m0\u001b[39m])\n\u001b[1;32m      4\u001b[0m     plt\u001b[39m.\u001b[39mxticks(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(dataset\u001b[39m.\u001b[39mcolumns) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m), dataset\u001b[39m.\u001b[39mcolumns[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], rotation\u001b[39m=\u001b[39m\u001b[39m90\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "if hasattr(model, \"coef_\"):\n",
    "    # Visualize the model coefficients as an example\n",
    "    plt.bar(range(len(dataset.columns) - 1), model.coef_[0])\n",
    "    plt.xticks(range(len(dataset.columns) - 1), dataset.columns[:-1], rotation=90)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Model has no coefficients to be visualized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE using your explainability method to explain why the MLP returns whatever it returns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checklist before submitting\n",
    "\n",
    "Please make sure to fulfil all these points:\n",
    "- I haven't changed cell 2 and in cell 3 only parameters of my model(s) that were not specified in the beginning.\n",
    "- I have set ``SEMINAR_TOPIC_NUMBER`` in the first box to my topic number and explain the correct model.\n",
    "- I can run the notebook from top to bottom without errors.\n",
    "- Is my code well documented?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
